{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1qykQy3Edqu",
        "colab_type": "code",
        "outputId": "11f437c5-7649-438e-976e-d2d37f84931e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "#@title Installing PyTorch \n",
        "!pip install torch==0.4\n",
        "!wget https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/util.py\n",
        "!wget https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/darknet.py\n",
        "!wget https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/pallete\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
            "\u001b[K     |████████████████████████████████| 484.0MB 28kB/s \n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "Successfully installed torch-0.4.0\n",
            "--2020-04-01 07:21:20--  https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/util.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7432 (7.3K) [text/plain]\n",
            "Saving to: ‘util.py’\n",
            "\n",
            "util.py             100%[===================>]   7.26K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-01 07:21:20 (138 MB/s) - ‘util.py’ saved [7432/7432]\n",
            "\n",
            "--2020-04-01 07:21:21--  https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/darknet.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9451 (9.2K) [text/plain]\n",
            "Saving to: ‘darknet.py’\n",
            "\n",
            "darknet.py          100%[===================>]   9.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-01 07:21:21 (138 MB/s) - ‘darknet.py’ saved [9451/9451]\n",
            "\n",
            "--2020-04-01 07:21:22--  https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/pallete\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 908 [application/octet-stream]\n",
            "Saving to: ‘pallete’\n",
            "\n",
            "pallete             100%[===================>]     908  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-01 07:21:22 (46.7 MB/s) - ‘pallete’ saved [908/908]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc4iHPOPEBeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Import dependencies\n",
        "from __future__ import division\n",
        "import time\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2 \n",
        "from util import *\n",
        "import argparse\n",
        "import os \n",
        "import os.path as osp\n",
        "from darknet import *\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import random\n",
        "import csv\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYqiOI837xpj",
        "colab_type": "code",
        "outputId": "8d6e8151-a7e0-4cf5-ad93-eac6942f7941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#@title Get weights and graph file for the model\n",
        "\n",
        "#Get weights file for the model\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "# Get YOLO graph file\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-01 07:21:23--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M   215KB/s    in 19m 4s  \n",
            "\n",
            "2020-04-01 07:40:29 (212 KB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n",
            "--2020-04-01 07:40:29--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg’\n",
            "\n",
            "yolov3.cfg          100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-01 07:40:29 (84.0 MB/s) - ‘yolov3.cfg’ saved [8342/8342]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBV3Wr6UUchD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Making directories for test photos\n",
        "!mkdir Images\n",
        "!mkdir Images_Detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLtGYrrQ9RUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Changing working directory\n",
        "os.chdir(os.getcwd()+'/'+'Images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeiiiiZv7ucK",
        "colab_type": "code",
        "outputId": "f001d887-96a1-46bc-d149-fe5da11340be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Get test images\n",
        "!wget https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/giraffe.jpg\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/messi.jpg\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img1.jpg\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img2.jpg\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img3.jpg\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img4.jpg\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-01 07:40:31--  https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png [following]\n",
            "--2020-04-01 07:40:31--  https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347445 (339K) [image/png]\n",
            "Saving to: ‘dog-cycle-car.png’\n",
            "\n",
            "dog-cycle-car.png   100%[===================>] 339.30K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-04-01 07:40:32 (6.47 MB/s) - ‘dog-cycle-car.png’ saved [347445/347445]\n",
            "\n",
            "--2020-04-01 07:40:32--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/giraffe.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 382965 (374K) [image/jpeg]\n",
            "Saving to: ‘giraffe.jpg’\n",
            "\n",
            "giraffe.jpg         100%[===================>] 373.99K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-04-01 07:40:33 (6.71 MB/s) - ‘giraffe.jpg’ saved [382965/382965]\n",
            "\n",
            "--2020-04-01 07:40:33--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/messi.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 126867 (124K) [image/jpeg]\n",
            "Saving to: ‘messi.jpg’\n",
            "\n",
            "messi.jpg           100%[===================>] 123.89K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-04-01 07:40:33 (3.82 MB/s) - ‘messi.jpg’ saved [126867/126867]\n",
            "\n",
            "--2020-04-01 07:40:34--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img1.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78771 (77K) [image/jpeg]\n",
            "Saving to: ‘img1.jpg’\n",
            "\n",
            "img1.jpg            100%[===================>]  76.92K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-04-01 07:40:34 (3.35 MB/s) - ‘img1.jpg’ saved [78771/78771]\n",
            "\n",
            "--2020-04-01 07:40:35--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img2.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 113300 (111K) [image/jpeg]\n",
            "Saving to: ‘img2.jpg’\n",
            "\n",
            "img2.jpg            100%[===================>] 110.64K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-04-01 07:40:35 (3.65 MB/s) - ‘img2.jpg’ saved [113300/113300]\n",
            "\n",
            "--2020-04-01 07:40:35--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img3.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102770 (100K) [image/jpeg]\n",
            "Saving to: ‘img3.jpg’\n",
            "\n",
            "img3.jpg            100%[===================>] 100.36K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-04-01 07:40:36 (3.18 MB/s) - ‘img3.jpg’ saved [102770/102770]\n",
            "\n",
            "--2020-04-01 07:40:36--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img4.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84988 (83K) [image/jpeg]\n",
            "Saving to: ‘img4.jpg’\n",
            "\n",
            "img4.jpg            100%[===================>]  83.00K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-04-01 07:40:36 (3.37 MB/s) - ‘img4.jpg’ saved [84988/84988]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypnOdfoA4-j_",
        "colab_type": "code",
        "outputId": "e26c4e4e-b2cc-4341-9df5-6151c8563061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoGBWedt5EKJ",
        "colab_type": "code",
        "outputId": "4e00d175-3d4d-47f3-d2a3-23b466631659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd content"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'content'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd1xmkVMLyqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Making directory for COCO names file\n",
        "!mkdir data\n",
        "os.chdir('./data')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXiVsY_tPb0F",
        "colab_type": "code",
        "outputId": "6c711f44-b817-472c-e30b-f524c986589d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#@title COCO names file\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-01 07:40:37--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘coco.names’\n",
            "\n",
            "\rcoco.names            0%[                    ]       0  --.-KB/s               \rcoco.names          100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-01 07:40:38 (192 MB/s) - ‘coco.names’ saved [625/625]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqLOznoKP9p9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_classes(namefile):\n",
        "  fp = open(namefile, 'r')\n",
        "  names = fp.read().split(\"\\n\")[:-1] #discard the last\n",
        "  return names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRwioCNcKKsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOLR4HS3PiLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COCO dataset has 80 different classes\n",
        "num_classes = 80\n",
        "classes = load_classes(\"coco.names\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF4jcEEO6OuE",
        "colab_type": "code",
        "outputId": "3c1131cb-28b9-47c8-a271-258f38ea666f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXKVOxES7Aiv",
        "colab_type": "code",
        "outputId": "00847275-e899-43c5-847f-8a174beac2aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images = os.getcwd() + '/Images'\n",
        "images_det = os.getcwd() + '/Images_Detection'\n",
        "print(images, images_det)\n",
        "batch_size = 1\n",
        "confidence = 0.5\n",
        "nms_thesh = 0.4\n",
        "reso = 416\n",
        "weights_file = \"yolov3.weights\"\n",
        "config_file = \"yolov3.cfg\"\n",
        "start = 0\n",
        "detect_image = False\n",
        "CUDA = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Images /content/Images_Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9R-wcjT6QgG",
        "colab_type": "code",
        "outputId": "785081c5-ad4d-45c4-dc60-be45ac70a8af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set up the network\n",
        "print(\"Loading network...\")\n",
        "model = Darknet(config_file)\n",
        "model.load_weights(weights_file)\n",
        "print(\"Network successfully loaded\")\n",
        "\n",
        "\n",
        "model.net_info[\"height\"] = reso\n",
        "inp_dim = int(model.net_info[\"height\"])\n",
        "assert inp_dim % 32 == 0\n",
        "assert inp_dim > 32\n",
        "\n",
        "# if GPU is available allocate the model\n",
        "if CUDA:\n",
        "  model.cuda()\n",
        "  \n",
        "# Set the model in evaluation mode\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading network...\n",
            "Network successfully loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Darknet(\n",
              "  (module_list): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_0): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_1): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_2): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_3): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (shortcut_4): EmptyLayer()\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_5): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_6): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_7): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (8): Sequential(\n",
              "      (shortcut_8): EmptyLayer()\n",
              "    )\n",
              "    (9): Sequential(\n",
              "      (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_9): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (10): Sequential(\n",
              "      (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_10): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (11): Sequential(\n",
              "      (shortcut_11): EmptyLayer()\n",
              "    )\n",
              "    (12): Sequential(\n",
              "      (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_12): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (13): Sequential(\n",
              "      (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_13): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (14): Sequential(\n",
              "      (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_14): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (15): Sequential(\n",
              "      (shortcut_15): EmptyLayer()\n",
              "    )\n",
              "    (16): Sequential(\n",
              "      (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_16): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (17): Sequential(\n",
              "      (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_17): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (18): Sequential(\n",
              "      (shortcut_18): EmptyLayer()\n",
              "    )\n",
              "    (19): Sequential(\n",
              "      (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_19): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (20): Sequential(\n",
              "      (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_20): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (21): Sequential(\n",
              "      (shortcut_21): EmptyLayer()\n",
              "    )\n",
              "    (22): Sequential(\n",
              "      (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_22): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (23): Sequential(\n",
              "      (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_23): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (24): Sequential(\n",
              "      (shortcut_24): EmptyLayer()\n",
              "    )\n",
              "    (25): Sequential(\n",
              "      (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_25): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (26): Sequential(\n",
              "      (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_26): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (27): Sequential(\n",
              "      (shortcut_27): EmptyLayer()\n",
              "    )\n",
              "    (28): Sequential(\n",
              "      (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_28): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (29): Sequential(\n",
              "      (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_29): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (30): Sequential(\n",
              "      (shortcut_30): EmptyLayer()\n",
              "    )\n",
              "    (31): Sequential(\n",
              "      (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_31): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (32): Sequential(\n",
              "      (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_32): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (33): Sequential(\n",
              "      (shortcut_33): EmptyLayer()\n",
              "    )\n",
              "    (34): Sequential(\n",
              "      (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_34): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (35): Sequential(\n",
              "      (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_35): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (36): Sequential(\n",
              "      (shortcut_36): EmptyLayer()\n",
              "    )\n",
              "    (37): Sequential(\n",
              "      (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_37): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (38): Sequential(\n",
              "      (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_38): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (39): Sequential(\n",
              "      (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_39): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (40): Sequential(\n",
              "      (shortcut_40): EmptyLayer()\n",
              "    )\n",
              "    (41): Sequential(\n",
              "      (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_41): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (42): Sequential(\n",
              "      (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_42): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (43): Sequential(\n",
              "      (shortcut_43): EmptyLayer()\n",
              "    )\n",
              "    (44): Sequential(\n",
              "      (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_44): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (45): Sequential(\n",
              "      (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_45): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (46): Sequential(\n",
              "      (shortcut_46): EmptyLayer()\n",
              "    )\n",
              "    (47): Sequential(\n",
              "      (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_47): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (48): Sequential(\n",
              "      (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_48): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (49): Sequential(\n",
              "      (shortcut_49): EmptyLayer()\n",
              "    )\n",
              "    (50): Sequential(\n",
              "      (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_50): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (51): Sequential(\n",
              "      (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_51): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (52): Sequential(\n",
              "      (shortcut_52): EmptyLayer()\n",
              "    )\n",
              "    (53): Sequential(\n",
              "      (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_53): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (54): Sequential(\n",
              "      (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_54): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (55): Sequential(\n",
              "      (shortcut_55): EmptyLayer()\n",
              "    )\n",
              "    (56): Sequential(\n",
              "      (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_56): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (57): Sequential(\n",
              "      (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_57): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (58): Sequential(\n",
              "      (shortcut_58): EmptyLayer()\n",
              "    )\n",
              "    (59): Sequential(\n",
              "      (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_59): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (60): Sequential(\n",
              "      (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_60): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (61): Sequential(\n",
              "      (shortcut_61): EmptyLayer()\n",
              "    )\n",
              "    (62): Sequential(\n",
              "      (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_62): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (63): Sequential(\n",
              "      (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_63): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (64): Sequential(\n",
              "      (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_64): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (65): Sequential(\n",
              "      (shortcut_65): EmptyLayer()\n",
              "    )\n",
              "    (66): Sequential(\n",
              "      (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_66): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (67): Sequential(\n",
              "      (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_67): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (68): Sequential(\n",
              "      (shortcut_68): EmptyLayer()\n",
              "    )\n",
              "    (69): Sequential(\n",
              "      (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_69): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (70): Sequential(\n",
              "      (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_70): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (71): Sequential(\n",
              "      (shortcut_71): EmptyLayer()\n",
              "    )\n",
              "    (72): Sequential(\n",
              "      (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_72): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (73): Sequential(\n",
              "      (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_73): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (74): Sequential(\n",
              "      (shortcut_74): EmptyLayer()\n",
              "    )\n",
              "    (75): Sequential(\n",
              "      (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_75): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (76): Sequential(\n",
              "      (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_76): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (77): Sequential(\n",
              "      (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_77): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (78): Sequential(\n",
              "      (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_78): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (79): Sequential(\n",
              "      (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_79): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (80): Sequential(\n",
              "      (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_80): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (81): Sequential(\n",
              "      (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (82): Sequential(\n",
              "      (Detection_82): DetectionLayer()\n",
              "    )\n",
              "    (83): Sequential(\n",
              "      (route_83): EmptyLayer()\n",
              "    )\n",
              "    (84): Sequential(\n",
              "      (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_84): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (85): Sequential(\n",
              "      (Upsample_85): Upsample(scale_factor=2, mode=bilinear)\n",
              "    )\n",
              "    (86): Sequential(\n",
              "      (route_86): EmptyLayer()\n",
              "    )\n",
              "    (87): Sequential(\n",
              "      (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_87): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (88): Sequential(\n",
              "      (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_88): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (89): Sequential(\n",
              "      (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_89): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (90): Sequential(\n",
              "      (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_90): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (91): Sequential(\n",
              "      (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_91): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (92): Sequential(\n",
              "      (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_92): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (93): Sequential(\n",
              "      (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (94): Sequential(\n",
              "      (Detection_94): DetectionLayer()\n",
              "    )\n",
              "    (95): Sequential(\n",
              "      (route_95): EmptyLayer()\n",
              "    )\n",
              "    (96): Sequential(\n",
              "      (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_96): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (97): Sequential(\n",
              "      (Upsample_97): Upsample(scale_factor=2, mode=bilinear)\n",
              "    )\n",
              "    (98): Sequential(\n",
              "      (route_98): EmptyLayer()\n",
              "    )\n",
              "    (99): Sequential(\n",
              "      (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_99): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (100): Sequential(\n",
              "      (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_100): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (101): Sequential(\n",
              "      (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_101): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (102): Sequential(\n",
              "      (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_102): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (103): Sequential(\n",
              "      (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_103): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (104): Sequential(\n",
              "      (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (Leaky_104): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (105): Sequential(\n",
              "      (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (106): Sequential(\n",
              "      (Detection_106): DetectionLayer()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqevrEIb9ckU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlEXX8CkOfkR",
        "colab_type": "text"
      },
      "source": [
        "Check imlist here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMqTQPhj-Swa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "imlist=imlist[:6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ythS8Jaa-V5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_ims = [cv2.imread(x) for x in imlist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg3aer9-CTPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_box(x, results):\n",
        "  #print(results)\n",
        "  c1 = tuple(x[1:3].int())\n",
        "  c2 = tuple(x[3:5].int())\n",
        "  img = results[int(x[0])]\n",
        "  #plt.imshow(img)\n",
        "  #plt.show()\n",
        "  cls = int(x[-1])\n",
        "  print(cls)\n",
        "  print(\"coordinates 1\",c1)\n",
        "  print(\"coordinates 2\",c2)\n",
        "  '''\n",
        "  color = random.choice(colors)\n",
        "  label = \"{0}\".format(classes[cls])\n",
        "  rect = cv2.rectangle(img, c1, c2,color, 2)\n",
        "  t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
        "  c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
        "  cv2.rectangle(img, c1, c2,color, -1)\n",
        "  cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1)\n",
        "  '''\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7-R1Ak2-cLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFCNjjYQ8Ba0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from util import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36xgUPfR80Qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_write_results(prediction, confidence, num_classes, nms_conf = 0.4):\n",
        "    conf_mask = (prediction[:,:,4] > confidence).float().unsqueeze(2)\n",
        "    prediction = prediction*conf_mask\n",
        "    \n",
        "    box_corner = prediction.new(prediction.shape)\n",
        "    box_corner[:,:,0] = (prediction[:,:,0] - prediction[:,:,2]/2)\n",
        "    box_corner[:,:,1] = (prediction[:,:,1] - prediction[:,:,3]/2)\n",
        "    box_corner[:,:,2] = (prediction[:,:,0] + prediction[:,:,2]/2) \n",
        "    box_corner[:,:,3] = (prediction[:,:,1] + prediction[:,:,3]/2)\n",
        "    prediction[:,:,:4] = box_corner[:,:,:4]\n",
        "    \n",
        "    batch_size = prediction.size(0)\n",
        "\n",
        "    write = False\n",
        "    \n",
        "\n",
        "    print(\"ax\")\n",
        "    for ind in range(batch_size):\n",
        "        image_pred = prediction[ind]          #image Tensor\n",
        "       #confidence threshholding \n",
        "       #NMS\n",
        "    \n",
        "        max_conf, max_conf_score = torch.max(image_pred[:,5:5+ num_classes], 1)\n",
        "        max_conf = max_conf.float().unsqueeze(1)\n",
        "        max_conf_score = max_conf_score.float().unsqueeze(1)\n",
        "        seq = (image_pred[:,:5], max_conf, max_conf_score)\n",
        "        image_pred = torch.cat(seq, 1)\n",
        "        \n",
        "        non_zero_ind =  (torch.nonzero(image_pred[:,4]))\n",
        "        try:\n",
        "            image_pred_ = image_pred[non_zero_ind.squeeze(),:].view(-1,7)\n",
        "        except:\n",
        "            continue\n",
        "        \n",
        "        if image_pred_.shape[0] == 0:\n",
        "            continue       \n",
        "#        \n",
        "  \n",
        "        #Get the various classes detected in the image\n",
        "        img_classes = unique(image_pred_[:,-1])  # -1 index holds the class index\n",
        "        \n",
        "        \n",
        "        for cls in img_classes:\n",
        "            #perform NMS\n",
        "              if(cls==0):\n",
        "          \n",
        "              #get the detections with one particular class\n",
        "                cls_mask = image_pred_*(image_pred_[:,-1] == cls).float().unsqueeze(1)\n",
        "                class_mask_ind = torch.nonzero(cls_mask[:,-2]).squeeze()\n",
        "                image_pred_class = image_pred_[class_mask_ind].view(-1,7)\n",
        "                \n",
        "                #sort the detections such that the entry with the maximum objectness\n",
        "                #confidence is at the top\n",
        "                conf_sort_index = torch.sort(image_pred_class[:,4], descending = True )[1]\n",
        "                image_pred_class = image_pred_class[conf_sort_index]\n",
        "                idx = image_pred_class.size(0)   #Number of detections\n",
        "                \n",
        "                for i in range(idx):\n",
        "                    #Get the IOUs of all boxes that come after the one we are looking at \n",
        "                    #in the loop\n",
        "                    try:\n",
        "                        ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i+1:])\n",
        "                    except ValueError:\n",
        "                        break\n",
        "                \n",
        "                    except IndexError:\n",
        "                        break\n",
        "                \n",
        "                    #Zero out all the detections that have IoU > treshhold\n",
        "                    iou_mask = (ious < nms_conf).float().unsqueeze(1)\n",
        "                    image_pred_class[i+1:] *= iou_mask       \n",
        "                \n",
        "                    #Remove the non-zero entries\n",
        "                    non_zero_ind = torch.nonzero(image_pred_class[:,4]).squeeze()\n",
        "                    image_pred_class = image_pred_class[non_zero_ind].view(-1,7)\n",
        "                    \n",
        "                batch_ind = image_pred_class.new(image_pred_class.size(0), 1).fill_(ind)      #Repeat the batch_id for as many detections of the class cls in the image\n",
        "                seq = batch_ind, image_pred_class\n",
        "                \n",
        "                if not write:\n",
        "                    output = torch.cat(seq,1)\n",
        "                    write = True\n",
        "                else:\n",
        "                    out = torch.cat(seq,1)\n",
        "                    output = torch.cat((output,out))\n",
        "   \n",
        "    try:\n",
        "        return output\n",
        "    except:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqkw-90--gOS",
        "colab_type": "code",
        "outputId": "f3d7aef5-3c89-416f-ea7c-384b1a32b1af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "\n",
        "\n",
        "leftover = 0\n",
        "batch_size=2\n",
        "if (len(im_dim_list) % batch_size):\n",
        "    leftover = 1\n",
        "\n",
        "if batch_size != 1:\n",
        "    num_batches = len(imlist) // batch_size + leftover            \n",
        "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
        "                        len(im_batches))]))  for i in range(num_batches)]  \n",
        "\n",
        "write = 0\n",
        "\n",
        "\n",
        "if CUDA:\n",
        "    im_dim_list = im_dim_list.cuda()\n",
        "\n",
        "start_det_loop = time.time()\n",
        "for i, batch in enumerate(im_batches):\n",
        "    print(len(batch))\n",
        "#load the image \n",
        "    start = time.time()\n",
        "    if CUDA:\n",
        "        batch = batch.cuda()\n",
        "    with torch.no_grad():\n",
        "        prediction = model(Variable(batch), CUDA)\n",
        "    num_classes=80\n",
        "    \n",
        "    prediction = new_write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
        "    \n",
        "    end = time.time()\n",
        "\n",
        "    if type(prediction) == int:\n",
        "        print(\"((((((\")\n",
        "        for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "            im_id = i*batch_size + im_num\n",
        "\n",
        "            print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "            print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
        "            print(\"----------------------------------------------------------\")\n",
        "        continue\n",
        "\n",
        "    print(len(prediction))\n",
        "    prediction[:,0] += i*batch_size    #transform the atribute from index in batch to index in imlist \n",
        "    print(len(prediction))\n",
        "    if not write:                      #If we have't initialised output\n",
        "        output = prediction  \n",
        "        write = 1\n",
        "    else:\n",
        "        output = torch.cat((output,prediction))\n",
        "    \n",
        "    print(output.shape)\n",
        "    for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "        im_id = i*batch_size + im_num\n",
        "        objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
        "\n",
        "        print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "        print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
        "        print(\"----------------------------------------------------------\")\n",
        "        \n",
        "    list(map(lambda x: write_box(x, loaded_ims), output))\n",
        "    \n",
        "\n",
        "    if CUDA:\n",
        "        torch.cuda.synchronize()       \n",
        "try:\n",
        "    output\n",
        "except NameError:\n",
        "    print (\"No detections were made\")\n",
        "    exit()\n",
        "\n",
        "im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())\n",
        "\n",
        "scaling_factor = torch.min(416/im_dim_list,1)[0].view(-1,1)\n",
        "\n",
        "\n",
        "output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2\n",
        "output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2\n",
        "\n",
        "\n",
        "\n",
        "output[:,1:5] /= scaling_factor\n",
        "\n",
        "for i in range(output.shape[0]):\n",
        "    output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
        "    output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])\n",
        "\n",
        "\n",
        "output_recast = time.time()\n",
        "class_load = time.time()\n",
        "colors = pkl.load(open(\"pallete\", \"rb\"))\n",
        "\n",
        "draw = time.time()\n",
        "\n",
        "\n",
        "\n",
        "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(images_det,x.split(\"/\")[-1]))\n",
        "\n",
        "list(map(cv2.imwrite, det_names, loaded_ims))\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"SUMMARY\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
        "print()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "ax\n",
            "((((((\n",
            "img2.jpg             predicted in  0.015 seconds\n",
            "Objects Detected:    \n",
            "----------------------------------------------------------\n",
            "giraffe.jpg          predicted in  0.015 seconds\n",
            "Objects Detected:    \n",
            "----------------------------------------------------------\n",
            "2\n",
            "ax\n",
            "3\n",
            "3\n",
            "torch.Size([3, 8])\n",
            "img4.jpg             predicted in  0.016 seconds\n",
            "Objects Detected:    \n",
            "----------------------------------------------------------\n",
            "messi.jpg            predicted in  0.016 seconds\n",
            "Objects Detected:    person person person\n",
            "----------------------------------------------------------\n",
            "0\n",
            "coordinates 1 (tensor(15, dtype=torch.int32, device='cuda:0'), tensor(96, dtype=torch.int32, device='cuda:0'))\n",
            "coordinates 2 (tensor(255, dtype=torch.int32, device='cuda:0'), tensor(325, dtype=torch.int32, device='cuda:0'))\n",
            "0\n",
            "coordinates 1 (tensor(387, dtype=torch.int32, device='cuda:0'), tensor(243, dtype=torch.int32, device='cuda:0'))\n",
            "coordinates 2 (tensor(414, dtype=torch.int32, device='cuda:0'), tensor(314, dtype=torch.int32, device='cuda:0'))\n",
            "0\n",
            "coordinates 1 (tensor(197, dtype=torch.int32, device='cuda:0'), tensor(127, dtype=torch.int32, device='cuda:0'))\n",
            "coordinates 2 (tensor(364, dtype=torch.int32, device='cuda:0'), tensor(324, dtype=torch.int32, device='cuda:0'))\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ax\n",
            "1\n",
            "1\n",
            "torch.Size([4, 8])\n",
            "img3.jpg             predicted in  0.017 seconds\n",
            "Objects Detected:    \n",
            "----------------------------------------------------------\n",
            "img1.jpg             predicted in  0.017 seconds\n",
            "Objects Detected:    person\n",
            "----------------------------------------------------------\n",
            "0\n",
            "coordinates 1 (tensor(15, dtype=torch.int32, device='cuda:0'), tensor(96, dtype=torch.int32, device='cuda:0'))\n",
            "coordinates 2 (tensor(255, dtype=torch.int32, device='cuda:0'), tensor(325, dtype=torch.int32, device='cuda:0'))\n",
            "0\n",
            "coordinates 1 (tensor(387, dtype=torch.int32, device='cuda:0'), tensor(243, dtype=torch.int32, device='cuda:0'))\n",
            "coordinates 2 (tensor(414, dtype=torch.int32, device='cuda:0'), tensor(314, dtype=torch.int32, device='cuda:0'))\n",
            "0\n",
            "coordinates 1 (tensor(197, dtype=torch.int32, device='cuda:0'), tensor(127, dtype=torch.int32, device='cuda:0'))\n",
            "coordinates 2 (tensor(364, dtype=torch.int32, device='cuda:0'), tensor(324, dtype=torch.int32, device='cuda:0'))\n",
            "0\n",
            "coordinates 1 (tensor(63, dtype=torch.int32, device='cuda:0'), tensor(20, dtype=torch.int32, device='cuda:0'))\n",
            "coordinates 2 (tensor(362, dtype=torch.int32, device='cuda:0'), tensor(404, dtype=torch.int32, device='cuda:0'))\n",
            "SUMMARY\n",
            "----------------------------------------------------------\n",
            "Task                     : Time Taken (in seconds)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXd6EJJW7lRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}

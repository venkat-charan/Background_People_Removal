# -*- coding: utf-8 -*-
"""instance_seg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S6tWcsg8QQRJbq3dbknQK9BlFEAcawXB
"""

from google.colab import drive
drive.mount('/content/drive')

# install dependencies: (use cu101 because colab has CUDA 10.1)
!pip install -U torch==1.4 torchvision==0.5 -f https://download.pytorch.org/whl/cu101/torch_stable.html 
!pip install cython pyyaml==5.1
!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'
import torch, torchvision
print(torch.__version__, torch.cuda.is_available())
!gcc --version
# opencv is pre-installed on colab

# install detectron2:
!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html

# You may need to restart your runtime prior to this, to let your installation take effect
# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import cv2
import random
from google.colab.patches import cv2_imshow
import glob
import os
import matplotlib.pyplot as plt

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog

img_dir = "/content/drive/Shared drives/EEE 598 PBCV/Good pics" # Enter Directory of all images 
data_path = os.path.join(img_dir,'*g')
files = glob.glob(data_path)
data = []
for f1 in files:
    img = cv2.imread(f1)
    data.append(img)

cfg = get_cfg()
# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model
# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
predictor = DefaultPredictor(cfg)
#outputs = predictor(im)

#function to check overlapping people and objects 
def overlap(maxx,maxy,minx,miny):
  if (minx < maxx and miny< maxy):
    return True
  else:
    return False

def masks(people,objects,im,im_num):
  #loop through all the people
  for i in range (people.number):
    wanted = []
    unwanted = []
    unwanted_obj = []
    max_size = people.getarea(1)
    #loop to find the biggest person in the image 
    for j in range (1,people.number+1):
      size = people.getarea(j)
      if (size>max_size):
        max_size = size
        wanted.append(j) 
      elif not wanted:
        wanted.append(1)
  print('biggest person found', wanted[0])
  #check if the other people in the image overlap with the 
  for i in range(2,people.number+1):
    if (i not in wanted) and overlap(people.maxx(1),people.maxy(1),people.minx(i),people.miny(i)):
      unwanted.append(i)
    elif(i not in wanted):
      wanted.append(i)
  print("wanted are {}".format(wanted))
  print("unwanted are {}".format(unwanted)) 

  for p in unwanted:  
    for k in range(1,objects.number+1):
      if(overlap(people.maxx(p),people.maxy(p),objects.minx(k),objects.miny(k)) and k not in unwanted_obj):
        unwanted_obj.append(k)
  print("unwanted objects are {}".format(unwanted_obj))

  k=np.zeros(im.shape)
  mask = np.zeros(im.shape)

  if len(unwanted)==1 :
    k[:,:,0]=np.where((people.getmask(unwanted[0]))==0,im[:,:,0],255)
    k[:,:,1]=np.where((people.getmask(unwanted[0]))==0,im[:,:,1],255)
    k[:,:,2]=np.where((people.getmask(unwanted[0]))==0,im[:,:,2],255)
    
    mask[:,:,0]=np.where((people.getmask(unwanted[0]))==0,mask[:,:,0],255)
    mask[:,:,1]=np.where((people.getmask(unwanted[0]))==0,mask[:,:,1],255)
    mask[:,:,2]=np.where((people.getmask(unwanted[0]))==0,mask[:,:,2],255) 
  
  elif not unwanted:
    k=im

  else:
    for i in range (len(unwanted)-1):
      k[:,:,0]=np.where((people.getmask(unwanted[i])+people.getmask(unwanted[i+1]))==0,im[:,:,0],255)
      k[:,:,1]=np.where((people.getmask(unwanted[i])+people.getmask(unwanted[i+1]))==0,im[:,:,1],255)
      k[:,:,2]=np.where((people.getmask(unwanted[i])+people.getmask(unwanted[i+1]))==0,im[:,:,2],255)
    
      mask[:,:,0]=np.where((people.getmask(unwanted[i])+people.getmask(unwanted[i+1]))==0,mask[:,:,0],255)
      mask[:,:,1]=np.where((people.getmask(unwanted[i])+people.getmask(unwanted[i+1]))==0,mask[:,:,1],255)
      mask[:,:,2]=np.where((people.getmask(unwanted[i])+people.getmask(unwanted[i+1]))==0,mask[:,:,2],255)
  
  if len(unwanted_obj)==1:
    k[:,:,0]=np.where((objects.getmask(unwanted_obj[0]))==0,k[:,:,0],255)
    k[:,:,1]=np.where((objects.getmask(unwanted_obj[0]))==0,k[:,:,1],255)
    k[:,:,2]=np.where((objects.getmask(unwanted_obj[0]))==0,k[:,:,2],255)

    mask[:,:,0]=np.where((objects.getmask(unwanted_obj[0]))==0,mask[:,:,0],255)
    mask[:,:,1]=np.where((objects.getmask(unwanted_obj[0]))==0,mask[:,:,1],255)
    mask[:,:,2]=np.where((objects.getmask(unwanted_obj[0]))==0,mask[:,:,2],255)
  else:
    for i in range (len(unwanted_obj)-1):
      k[:,:,0]=np.where((objects.getmask(unwanted_obj[i])+objects.getmask(unwanted_obj[i+1]))==0,im[:,:,0],255)
      k[:,:,1]=np.where((objects.getmask(unwanted_obj[i])+objects.getmask(unwanted_obj[i+1]))==0,im[:,:,1],255)
      k[:,:,2]=np.where((objects.getmask(unwanted_obj[i])+objects.getmask(unwanted_obj[i+1]))==0,im[:,:,2],255)
      
      mask[:,:,0]=np.where((objects.getmask(unwanted_obj[i])+objects.getmask(unwanted_obj[i+1]))==0,mask[:,:,0],255)
      mask[:,:,1]=np.where((objects.getmask(unwanted_obj[i])+objects.getmask(unwanted_obj[i+1]))==0,mask[:,:,1],255)
      mask[:,:,2]=np.where((objects.getmask(unwanted_obj[i])+objects.getmask(unwanted_obj[i+1]))==0,mask[:,:,2],255)
  
  k = cv2.resize(k,(256,256)) 
  mask = cv2.resize(mask,(256,256))
  cv2.imwrite(os.path.join('/content/drive/My Drive/Masks','{}.png'.format(str(im_num))),mask)
  cv2.imwrite(os.path.join('/content/drive/My Drive/Images','{}.png'.format(str(im_num))),k)
  
  #cv2_imshow(k)
  #cv2_imshow(mask)

class dots:

  def __init__(self):
    self.number=0
    self.ip=dict()
    self.masks=dict()
    self.coords=dict()
    self.area=dict()

  def add(self,mask,coord):
    self.number+=1

    p=coord.tensor.cpu().numpy()
    self.ip[self.number]=(mask,coord)
    self.masks[self.number]=mask.cpu().numpy().astype('int')
    self.coords[self.number]=p
    self.area[self.number]= (p[0][2]-p[0][0])*(p[0][3]-p[0][1])

  def getmask(self,num):
    if(num>self.number):
      print("Doesen't exist {}".format(num))

    else:

      return self.masks[num]

  def getip(self,num):
    if(num>self.number):
      print("Doesen't exist {}".format(num))

    else:

      return self.ip[num]  

  def getcoord(self,num):
    if(num>self.number):
      print("Doesen't exist {}".format(num))

    else:

      return self.coords[num]

  def getarea(self,num):
    if(num>self.number):
      print("Doesen't exist {}".format(num))

    else:

      return self.area[num]
      
  def minx(self,num):
    if(num>self.number):
      print("Doesen't exist")

    else:

      return self.coords[num][0][0]

  def miny(self,num):
    if(num>self.number):
      print("Doesen't exist")

    else:

      return self.coords[num][0][1]

  def maxx(self,num):
    if(num>self.number):
      print("Doesen't exist")

    else:

      return self.coords[num][0][2]

  def maxy(self,num):
    if(num>self.number):
      print("Doesen't exist")

    else:

      return self.coords[num][0][3]

def segregation(outputs):

  people=dots()
  objects=dots()

  for i in range(len(outputs["instances"].pred_classes)):
    if(outputs["instances"].pred_classes[i]==0):
      people.add(outputs["instances"].pred_masks[i],outputs["instances"].pred_boxes[i])
    
    else:
      objects.add(outputs["instances"].pred_masks[i],outputs["instances"].pred_boxes[i])
  return people,objects

def overlap(cod1,cod2):

  if(cod1[0][3]<cod2[0][1] or cod2[0][3]<cod1[0][1]):
    return False

  if(cod1[0][0] > cod2[0][2] or cod2[0][0]>cod1[0][2]):
    return False

  return True

def overlappeep(ob,wanted,people):
  peep=[]
  peepset=set()
  for i in range(1,ob.number+1):
    for j in wanted:
      print(i,j)
      if(overlap(ob.getcoord(i),people.getcoord(j))):
        peep.append(i)
        peepset.add(i)
        print("* {}".format(len(wanted)))

  return peep,peepset

def maskadd(ob,sets,maskf):
  for i in range(1,ob.number+1):
    if(i not in sets):
      maskf+=ob.getmask(i)
  
  return maskf

def masks(people,objects,im,im_num):
  maxArea=-1
  maxAreaIndex=-1
  for i in range(1,people.number+1):
    if(people.getarea(i)>maxArea):
      maxArea=people.getarea(i)
      maxAreaIndex=i
  
  print('max area {}'.format(maxAreaIndex))
  wanted=[maxAreaIndex]



  wanted,wantedset=overlappeep(people,wanted,people)
  
  wantedobj,wantedobjset=overlappeep(objects,wanted,people)

  print('wanted people {}'.format(wanted))
  mask=np.zeros(im.shape[:-1])
  

  mask=maskadd(people,wantedset,mask)

  mask=maskadd(objects,wantedobjset,mask)
  m = np.zeros(im.shape)
  incomp=np.zeros(im.shape)

  for i in range(3):
    incomp[:,:,i]=np.where(mask==0,im[:,:,i],255)
    m[:,:,i]=np.where(mask==0,m[:,:,i],255)
  
  incomp = cv2.resize(incomp,(256,256)) 
  m = cv2.resize(m,(256,256))
  cv2.imwrite(os.path.join('/content/drive/My Drive/Masks','{}.png'.format(str(im_num))),m)
  cv2.imwrite(os.path.join('/content/drive/My Drive/Images','{}.png'.format(str(im_num))),incomp)
  cv2_imshow(incomp)
  cv2_imshow(m)

for i in range (len(data)):
  outputs = predictor(data[i])
  p,o=segregation(outputs)
  masks(p,o,data[i],i)

p.getcoord(1)[0][1]

plt.imshow(data[i])

